{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a37b7ae7",
      "metadata": {
        "id": "a37b7ae7"
      },
      "source": [
        "# TP : Spark Streaming\n",
        "\n",
        "**Objectif :** analyser en temps réel des messages texte envoyés via un socket et calculer le **nombre d’occurrences de chaque mot toutes les 5 secondes**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b092adc",
      "metadata": {
        "id": "9b092adc"
      },
      "source": [
        "## 1) Installer PySpark\n",
        "\n",
        "Installation de PySpark dans le runtime Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ec3a26b9",
      "metadata": {
        "id": "ec3a26b9"
      },
      "outputs": [],
      "source": [
        "!pip -q install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efddfd2b",
      "metadata": {
        "id": "efddfd2b"
      },
      "source": [
        "## (Optionnel) Masquer le warning de dépréciation\n",
        "\n",
        "Spark peut afficher un `FutureWarning` indiquant que DStream est déprécié. Ce n'est **pas** une erreur. Ici on le masque pour un affichage plus propre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cbe7faef",
      "metadata": {
        "id": "cbe7faef"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d643a13",
      "metadata": {
        "id": "7d643a13"
      },
      "source": [
        "## 2) Créer un fichier de messages (pour l'envoi aléatoire)\n",
        "\n",
        "Conformément à la consigne (lecture aléatoire depuis un fichier), on prépare `messages.txt` :  \n",
        "- **1 ligne = 1 message**\n",
        "- le serveur socket choisira **au hasard** une ligne à envoyer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6f31ce43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f31ce43",
        "outputId": "db01c878-61d5-440e-acbc-061ece739f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fichier utilisé : /content/messages.txt\n",
            "Contenu :\n",
            "spark streaming dstream\n",
            "spark spark streaming\n",
            "big data spark\n",
            "stream processing with spark\n",
            "hello spark streaming\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "messages_path = Path(\"messages.txt\")\n",
        "\n",
        "# Si le fichier n'existe pas, on le crée avec quelques messages d'exemple.\n",
        "if not messages_path.exists():\n",
        "    messages_path.write_text(\n",
        "        \"\\n\".join([\n",
        "            \"spark streaming dstream\",\n",
        "            \"spark spark streaming\",\n",
        "            \"big data spark\",\n",
        "            \"stream processing with spark\",\n",
        "            \"hello spark streaming\"\n",
        "        ]) + \"\\n\",\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "\n",
        "print(\"Fichier utilisé :\", messages_path.resolve())\n",
        "print(\"Contenu :\")\n",
        "print(messages_path.read_text(encoding=\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fb97c14",
      "metadata": {
        "id": "4fb97c14"
      },
      "source": [
        "## 3) Créer un serveur socket simulant un flux de données\n",
        "\n",
        "Le serveur :  \n",
        "- écoute sur **localhost:9999**  \n",
        "- accepte une connexion (Spark se connectera automatiquement)  \n",
        "- envoie **une ligne aléatoire** du fichier toutes les **2 secondes**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "287dca71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "287dca71",
        "outputId": "a7aa52a5-0b86-487b-879e-55d178964d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serveur socket démarré.\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "import time\n",
        "import threading\n",
        "import random\n",
        "\n",
        "HOST = \"localhost\"\n",
        "PORT = 9999\n",
        "SEND_EVERY_SECONDS = 2\n",
        "\n",
        "def start_socket_server(file_path: str, host: str = HOST, port: int = PORT, interval_s: float = SEND_EVERY_SECONDS):\n",
        "    # Charger les messages (lignes non vides)\n",
        "    lines = [ln.strip() for ln in Path(file_path).read_text(encoding=\"utf-8\").splitlines() if ln.strip()]\n",
        "    if not lines:\n",
        "        raise ValueError(\"Le fichier ne contient aucune ligne non vide.\")\n",
        "\n",
        "    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    # Utile si tu relances la cellule : permet de réutiliser le port rapidement.\n",
        "    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
        "\n",
        "    server.bind((host, port))\n",
        "    server.listen(1)\n",
        "    print(f\"[SocketServer] En écoute sur {host}:{port} ...\")\n",
        "\n",
        "    conn, addr = server.accept()\n",
        "    print(f\"[SocketServer] Client connecté : {addr}\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            msg = random.choice(lines)\n",
        "            conn.sendall((msg + \"\\n\").encode(\"utf-8\"))\n",
        "            print(f\"[SocketServer] envoyé -> {msg}\")\n",
        "            time.sleep(interval_s)\n",
        "    except Exception as e:\n",
        "        print(\"[SocketServer] arrêt :\", repr(e))\n",
        "    finally:\n",
        "        try:\n",
        "            conn.close()\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            server.close()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Lancer le serveur dans un thread (daemon=True => s'arrête avec le runtime)\n",
        "server_thread = threading.Thread(\n",
        "    target=start_socket_server,\n",
        "    kwargs={\"file_path\": str(messages_path)},\n",
        "    daemon=True\n",
        ")\n",
        "server_thread.start()\n",
        "\n",
        "print(\"Serveur socket démarré.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d571454c",
      "metadata": {
        "id": "d571454c"
      },
      "source": [
        "## 4) Créer un `StreamingContext`\n",
        "\n",
        "Le TP demande un calcul **toutes les 5 secondes** → `batch_sec = 5`.\n",
        "\n",
        "⚠️ Selon les versions, `ssc.batchDuration` peut ne pas exister (AttributeError).  \n",
        "On affiche donc **la valeur qu'on a définie** (et on peut aussi lire via `_jssc` si besoin).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a5634527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5634527",
        "outputId": "9fd23764-70b3-484f-c4f1-d79f5e0ec678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SocketServer] En écoute sur localhost:9999 ...\n",
            "StreamingContext créé avec batchDuration = 5 secondes\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "\n",
        "# Si un StreamingContext existait déjà (ex. re-run), on essaie de l'arrêter proprement.\n",
        "try:\n",
        "    if \"ssc\" in globals() and ssc is not None:\n",
        "        ssc.stop(stopSparkContext=False, stopGraceFully=True)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# SparkContext unique (Colab)\n",
        "sc = SparkContext.getOrCreate()\n",
        "sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "batch_sec = 5\n",
        "ssc = StreamingContext(sc, batch_sec)\n",
        "\n",
        "print(\"StreamingContext créé avec batchDuration =\", batch_sec, \"secondes\")\n",
        "\n",
        "# Optionnel : récupérer la durée via l'objet Java (si disponible)\n",
        "try:\n",
        "    print(\"Batch duration (via _jssc) =\", ssc._jssc.batchDuration().milliseconds() / 1000, \"secondes\")\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70cfcb0f",
      "metadata": {
        "id": "70cfcb0f"
      },
      "source": [
        "## 5) Lire les données sous forme de DStream + WordCount\n",
        "\n",
        "Pipeline demandé :  \n",
        "```python\n",
        "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
        "words = lines.flatMap(lambda line: line.split(\" \"))\n",
        "pairs = words.map(lambda w: (w, 1))\n",
        "counts = pairs.reduceByKey(lambda a, b: a + b)\n",
        "counts.pprint()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7a2f9cf2",
      "metadata": {
        "id": "7a2f9cf2"
      },
      "outputs": [],
      "source": [
        "# Lecture du flux texte depuis le socket\n",
        "lines = ssc.socketTextStream(HOST, PORT)\n",
        "\n",
        "# Transformations : découpe en mots, puis (mot,1), puis somme par mot\n",
        "words = lines.flatMap(lambda line: line.split(\" \"))\n",
        "pairs = words.map(lambda w: (w, 1))\n",
        "counts = pairs.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Affichage dans la console\n",
        "counts.pprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d07086",
      "metadata": {
        "id": "f4d07086"
      },
      "source": [
        "## 6) Démarrer le streaming et afficher les résultats (30 secondes)\n",
        "\n",
        "Le TP demande :\n",
        "- `ssc.start()`\n",
        "- `ssc.awaitTerminationOrTimeout(30)`\n",
        "- `ssc.stop(stopSparkContext=False)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d895e862",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d895e862",
        "outputId": "bb9320f1-cae6-4c6d-c07c-9253accd34d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SocketServer] Client connecté : ('127.0.0.1', 55458)\n",
            "[SocketServer] envoyé -> hello spark streaming\n",
            "[SocketServer] envoyé -> spark spark streaming\n",
            "[SocketServer] envoyé -> stream processing with spark\n",
            "[SocketServer] envoyé -> big data spark\n",
            "[SocketServer] envoyé -> big data spark\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:25:30\n",
            "-------------------------------------------\n",
            "('hello', 1)\n",
            "('streaming', 2)\n",
            "('spark', 3)\n",
            "\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:25:35\n",
            "-------------------------------------------\n",
            "('with', 1)\n",
            "('big', 1)\n",
            "('stream', 1)\n",
            "('processing', 1)\n",
            "('spark', 2)\n",
            "('data', 1)\n",
            "\n",
            "[SocketServer] envoyé -> hello spark streaming\n",
            "[SocketServer] envoyé -> big data spark\n",
            "[SocketServer] envoyé -> spark streaming dstream\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:25:40\n",
            "-------------------------------------------\n",
            "('big', 2)\n",
            "('hello', 1)\n",
            "('streaming', 1)\n",
            "('data', 2)\n",
            "('spark', 3)\n",
            "\n",
            "[SocketServer] envoyé -> big data spark\n",
            "[SocketServer] envoyé -> big data spark\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:25:45\n",
            "-------------------------------------------\n",
            "('streaming', 1)\n",
            "('dstream', 1)\n",
            "('big', 1)\n",
            "('spark', 2)\n",
            "('data', 1)\n",
            "\n",
            "[SocketServer] envoyé -> stream processing with spark\n",
            "[SocketServer] envoyé -> hello spark streaming\n",
            "[SocketServer] envoyé -> spark streaming dstream\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:25:50\n",
            "-------------------------------------------\n",
            "('big', 1)\n",
            "('with', 1)\n",
            "('hello', 1)\n",
            "('streaming', 1)\n",
            "('data', 1)\n",
            "('spark', 3)\n",
            "('stream', 1)\n",
            "('processing', 1)\n",
            "\n",
            "[SocketServer] envoyé -> spark streaming dstream\n",
            "[SocketServer] envoyé -> spark spark streaming\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:25:55\n",
            "-------------------------------------------\n",
            "('streaming', 2)\n",
            "('dstream', 2)\n",
            "('spark', 2)\n",
            "\n",
            "[SocketServer] envoyé -> stream processing with spark\n",
            "[SocketServer] arrêt : BrokenPipeError(32, 'Broken pipe')\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:26:00\n",
            "-------------------------------------------\n",
            "('streaming', 1)\n",
            "('spark', 2)\n",
            "\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:26:05\n",
            "-------------------------------------------\n",
            "\n",
            "-------------------------------------------\n",
            "Time: 2026-01-21 21:26:10\n",
            "-------------------------------------------\n",
            "\n",
            "✅ Streaming terminé.\n"
          ]
        }
      ],
      "source": [
        "# Démarrage\n",
        "ssc.start()\n",
        "\n",
        "# Laisser tourner 30 secondes\n",
        "ssc.awaitTerminationOrTimeout(30)\n",
        "\n",
        "# Arrêt propre (on garde le SparkContext)\n",
        "ssc.stop(stopSparkContext=False, stopGraceFully=True)\n",
        "\n",
        "print(\"✅ Streaming terminé.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc46dd8",
      "metadata": {
        "id": "ddc46dd8"
      },
      "source": [
        "## Questions (réponses)\n",
        "\n",
        "**4) Qu’est-ce qu’un micro-batch dans DStream ?**  \n",
        "Un **micro-batch** est un petit lot de données collectées pendant une fenêtre de temps fixe (ex. **5 secondes**). Spark Streaming traite chaque micro-batch comme un job Spark classique.\n",
        "\n",
        "**5) Sur quelle structure repose un DStream ?**  \n",
        "Un DStream repose sur une **séquence de RDD** : à chaque intervalle de batch, Spark crée un **RDD** contenant les données reçues sur cette fenêtre.\n",
        "\n",
        "**6) Quelle est la durée du batch utilisée ?**  \n",
        "La durée du batch est **5 secondes** (`StreamingContext(sc, 5)`).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "70cfcb0f"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}